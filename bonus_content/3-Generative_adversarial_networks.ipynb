{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative adversarial networks\n",
    "\n",
    "In the last notebook, we saw how we could use probabilistic generative modelling to generate synthetic images. This is cool for generative AI, but also for things like data augmentation, etc. Unfortunately, the VAE quality wasn't great. Generative adversarial networks (GANs) are an alternative. The idea is very simple we will use a generator (decoder) $G(z)$ to take a random sample and generate an image. We will train this decoder to generate realistic images like those in our training set. We will then add a discriminator $D(G(z))$, that tries to classify whether an image was real or fake. \n",
    "\n",
    "The generator is going to try to minimise this function:\n",
    "$$ \\mathbb{E}_x [\\log (D(x))] + \\mathbb{E}_z [\\log (1-D(G(z)))] $$\n",
    "while the discriminator tries to maximise it.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Can you try to derive this loss function? Hint, think about the cross entropy loss. If the generator is trying to trick the discriminator, it wants the discriminator to be maximally unsure of whether an image is real or fake. On the other hand, the discriminator wants to be force the generator to generate more realistic images, by becoming very good at telling real images from fake ones. Sounds convoluted? It is. We call this a minimax loss.  \n",
    "\n",
    "## Building our GAN\n",
    "\n",
    "Let's implement something a bit like a [DCGAN](https://arxiv.org/pdf/1511.06434.pdf). GANS are notoriously hard to train because of the inherent battle going on in the loss, and this paper has some helpful tips on making them work. Still, you will waste a lot of time on hyperparameter tuning (selecting batch sizes, learning rates, etc.) getting GANs to work - there is even an entire document on [GAN hacks](https://github.com/soumith/ganhacks). For this reason, I dislike them intensely as generative models.\n",
    "\n",
    "However, this kind of training is very useful to prevent adversarial attacks (remember we looked at some of these earlier in the unit?), to help with data imbalance, and in a number of strategies to make neural networks fairer and less prone to bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by building a discriminator - this will try to tell if our image is real or fake\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self,channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # We have to use all sorts or architecture tricks to get this to work. Otherwise the GAN will find some sneaky shortcut and \n",
    "        # fail to train\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(channels,32,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(32,64,kernel_size=4,stride=2, padding=1, bias=False),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(256,1,kernel_size=2,stride=1,padding=0,bias=False),\n",
    "                                     nn.Flatten(),\n",
    "                                     nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will build a generator, this will take random noise in and generate an image\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #input latent_dim = 100\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Unflatten(dim=-1,unflattened_size=(-1,1,1)),\n",
    "                                     nn.ConvTranspose2d(100,256,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64,32,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32,3,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.Tanh())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to use a specific weight intitialisation to make it work too\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data = torchvision.datasets.CIFAR10(root='./data/',transform=transform)\n",
    "train_loader = DataLoader(data,batch_size=64,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "weights_init(generator)\n",
    "weights_init(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train the model. You'll note I am not implementing the loss abve directly. Instead I'm just going to alternate between tricking my discriminator and correcting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_g_loss = None  # exponential moving average\n",
    "avg_d_loss = None  # exponential moving average\n",
    "n_epochs = 100\n",
    "\n",
    "optim_1 = torch.optim.Adam(generator.parameters(),lr=2e-5, betas=(0.5, 0.999))\n",
    "optim_2 = torch.optim.Adam(discriminator.parameters(),lr=2e-5, betas=(0.5, 0.999)) # Note different learning rates - I don't want my discriminator collapsing first\n",
    "\n",
    "# This is only going to work if I can manage to find an equilibrium between the losses\n",
    "    \n",
    "disc_loss = nn.BCELoss()\n",
    "\n",
    "for step in range(n_epochs):\n",
    "\n",
    "    t = tqdm(total=len(train_loader))\n",
    "\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        im,_ = batch\n",
    "        \n",
    "        im = im.to(device)*2-1\n",
    "        \n",
    "        ims_fake = generator(torch.randn(im.shape[0],100,device=device))\n",
    "        \n",
    "        # Make some noisy labels - see GAN hacks, ideally this would be just ones and zeros\n",
    "        real_labels = torch.ones((im.shape[0],1),device=device) - 0.2*torch.rand((im.shape[0],1),device=device)\n",
    "        fake_labels = torch.zeros((im.shape[0],1),device=device) + 0.2*torch.rand((im.shape[0],1),device=device)\n",
    "            \n",
    "        # Generator step\n",
    "        optim_1.zero_grad()\n",
    "        fake_pred = discriminator(ims_fake) \n",
    "        loss = disc_loss(fake_pred,real_labels) \n",
    "        loss.backward() \n",
    "        optim_1.step()\n",
    "\n",
    "    \n",
    "        \n",
    "        if avg_g_loss is None:\n",
    "            avg_g_loss = loss.item()\n",
    "        else:\n",
    "            avg_g_loss = 0.95*avg_g_loss + 0.05*loss.item()\n",
    "        \n",
    "        #Discriminator  step\n",
    "        optim_2.zero_grad()\n",
    "        fake_pred = discriminator(ims_fake.detach()) # Note that we detach the image to prevent gradient flow here \n",
    "        real_pred = discriminator(im)\n",
    "        \n",
    "        real_loss = disc_loss(real_pred,real_labels)\n",
    "        fake_loss = disc_loss(fake_pred,fake_labels)\n",
    "        \n",
    "        loss = (real_loss + fake_loss)/2.0\n",
    "        loss.backward()    \n",
    "        optim_2.step()\n",
    "\n",
    "        if avg_d_loss is None:\n",
    "            avg_d_loss = loss.item()\n",
    "        else:\n",
    "            avg_d_loss = 0.95*avg_d_loss + 0.05*loss.item()            \n",
    "    \n",
    "        # Some visualisation during training.\n",
    "        t.update(1)\n",
    "        t.set_description(f\"Iter: {step}. Average Generator Loss: {avg_g_loss:.04f} Average Discriminator Loss: {avg_d_loss:.04f}\")\n",
    "    t.reset()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(0.5*im[0,:,:,:].transpose(0,2).cpu()+0.5)\n",
    "    plt.title('Real image')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(0.5*ims_fake[0,:,:,:].transpose(0,2).detach().cpu()+0.5)\n",
    "    plt.title('Fake image')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_fake.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Let's inspect some samples. Note the [checkerboard-like artifacts](https://distill.pub/2016/deconv-checkerboard/)? These could be avoided if we replace the transposed convolution and striding with an upsampling (bi-linear interpolation) step and conv operation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ims = generator(torch.randn(25,100,device=device))*0.5+0.5\n",
    "grid_im = torchvision.utils.make_grid(Ims, nrow=5).transpose(0,2).cpu()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(grid_im)\n",
    "plt.title('Generated images')\n",
    "train_loader = DataLoader(data,batch_size=25,shuffle=True)\n",
    "ims,_ = next(iter(train_loader))\n",
    "grid_im = torchvision.utils.make_grid(ims, nrow=5).transpose(0,2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(grid_im)\n",
    "plt.title('Real images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GANs\n",
    "\n",
    "Nice, those look pretty good. But what if we wanted to condition our generation based on a class label or some other information. Easy. We'll just augment the latent space and discriminator input with the extra input. Let's train a conditional GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by building a conditional discriminator - this will try to tell if our image is real or fake, conditioned on a class\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self,channels=3,num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Conv2d(channels,32,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(32,64,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.LeakyReLU(0.2,inplace=True),\n",
    "                                     nn.Flatten())\n",
    "\n",
    "        self.classifier  = nn.Sequential(nn.Linear(2048 + num_classes,1,bias=False),\n",
    "                                     nn.Sigmoid())\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self,x,labels):\n",
    "        \n",
    "        x_in = torch.hstack((self.encoder(x), torch.nn.functional.one_hot(labels,self.num_classes)))\n",
    "        \n",
    "        return self.classifier(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will build a generator, this will take random noise in and generate an image\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Unflatten(dim=-1,unflattened_size=(-1,1,1)),\n",
    "                                     nn.ConvTranspose2d(100,256,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.ConvTranspose2d(64,32,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.LeakyReLU(),\n",
    "                                     nn.ConvTranspose2d(32,3,kernel_size=4,stride=2,padding=1),\n",
    "                                     nn.Tanh())\n",
    "        \n",
    "    def forward(self,x,labels):\n",
    "        \n",
    "        x_in = torch.hstack((x, torch.nn.functional.one_hot(labels,self.num_classes)))\n",
    "        \n",
    "        return self.decoder(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ConditionalGenerator(num_classes=10).to(device)\n",
    "discriminator = ConditionalDiscriminator(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_g_loss = None  # exponential moving average\n",
    "avg_d_loss = None  # exponential moving average\n",
    "n_epochs = 100\n",
    "\n",
    "optim_1 = torch.optim.Adam(generator.parameters(),lr=2e-5, betas=(0.5, 0.999))\n",
    "optim_2 = torch.optim.Adam(discriminator.parameters(),lr=2e-5, betas=(0.5, 0.999)) # Note different learning rates - I don't want my discriminator collapsing first\n",
    "\n",
    "# This is only going to work if I can manage to find an equilibrium between the losses\n",
    "    \n",
    "disc_loss = nn.BCELoss()\n",
    "\n",
    "for step in range(n_epochs):\n",
    "\n",
    "    t = tqdm(total=len(train_loader))\n",
    "\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        im,labels = batch\n",
    "        \n",
    "        im = im.to(device)*2-1\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        ims_fake = generator(torch.randn(im.shape[0],90,device=device),labels)\n",
    "        \n",
    "        # Make some noisy labels - see GAN hacks, ideally this would be just ones and zeros\n",
    "        real_labels = torch.ones((im.shape[0],1),device=device) - 0.2*torch.rand((im.shape[0],1),device=device)\n",
    "        fake_labels = torch.zeros((im.shape[0],1),device=device) + 0.2*torch.rand((im.shape[0],1),device=device)\n",
    "            \n",
    "        # Generator step\n",
    "        optim_1.zero_grad()\n",
    "        fake_pred = discriminator(ims_fake,labels) \n",
    "        loss = disc_loss(fake_pred,real_labels) \n",
    "        loss.backward() \n",
    "        optim_1.step()\n",
    "\n",
    "    \n",
    "        \n",
    "        if avg_g_loss is None:\n",
    "            avg_g_loss = loss.item()\n",
    "        else:\n",
    "            avg_g_loss = 0.95*avg_g_loss + 0.05*loss.item()\n",
    "        \n",
    "        #Discriminator  step\n",
    "        optim_2.zero_grad()\n",
    "        fake_pred = discriminator(ims_fake.detach(),labels) # Note that we detach the image to prevent gradient flow here \n",
    "        real_pred = discriminator(im,labels)\n",
    "        \n",
    "        real_loss = disc_loss(real_pred,real_labels)\n",
    "        fake_loss = disc_loss(fake_pred,fake_labels)\n",
    "        \n",
    "        loss = (real_loss + fake_loss)/2.0\n",
    "        loss.backward()    \n",
    "        optim_2.step()\n",
    "\n",
    "        if avg_d_loss is None:\n",
    "            avg_d_loss = loss.item()\n",
    "        else:\n",
    "            avg_d_loss = 0.95*avg_d_loss + 0.05*loss.item()            \n",
    "    \n",
    "        # Some visualisation during training.\n",
    "        t.update(1)\n",
    "        t.set_description(f\"Iter: {step}. Average Generator Loss: {avg_g_loss:.04f} Average Discriminator Loss: {avg_d_loss:.04f}\")\n",
    "    t.reset()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(0.5*im[0,:,:,:].transpose(0,2).cpu()+0.5)\n",
    "    plt.title('Real image')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(0.5*ims_fake[0,:,:,:].transpose(0,2).detach().cpu()+0.5)\n",
    "    plt.title('Fake image')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 3\n",
    "Ims = generator(torch.randn(25,90,device=device),class_label*torch.ones((25,),device=device).long())*0.5+0.5\n",
    "grid_im = torchvision.utils.make_grid(Ims, nrow=5).transpose(0,2).cpu()\n",
    "plt.imshow(grid_im)\n",
    "plt.title('Generated images class %d'%class_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are meant to be cats..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
